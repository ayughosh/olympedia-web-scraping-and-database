{
    "sourceFile": "app.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 23,
            "patches": [
                {
                    "date": 1754545384213,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1754545480789,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -163,9 +163,10 @@\n             details[\"died\"],\r\n             details[\"nationality\"],\r\n             details[\"roles\"],\r\n             details[\"affiliations\"],\r\n-            Json(details[\"medals_og\"])\r\n+            Json(details[\"medals_og\"]),\r\n+            Json(details[\"events\"]),\r\n         ))\r\n \r\n         time.sleep(0.5)\r\n     \r\n"
                },
                {
                    "date": 1754564152308,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -174,9 +174,9 @@\n if to_insert:\r\n     execute_values(cur, \"\"\"\r\n       INSERT INTO athletes\r\n         (athlete_id, used_name, full_name, sex, born, died,\r\n-         nationality, roles, affiliations, medals_og)\r\n+         nationality, roles, affiliations, medals_og, events)\r\n       VALUES %s\r\n     \"\"\",   to_insert)\r\n     conn.commit()\r\n     print(f\"Inserted {len(to_insert)} new athletes.\")\r\n"
                },
                {
                    "date": 1754567844607,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -102,9 +102,9 @@\n                 \r\n     events=[]\r\n     #Locate the results table(first table after h2 that says \"Results\")\r\n     hdr=soup.find(\"h2\",string=lambda t:t and \"Results\" in t)\r\n-    res_tbl=soup.find_next_sibling(\"table\") if hdr else None\r\n+    res_tbl=hdr.find_next_sibling(\"table\") if hdr else None\r\n     \r\n     if res_tbl:\r\n         #Skip the header row\r\n         for tr in res_tbl.select(\"tbody tr\"):\r\n"
                },
                {
                    "date": 1754621737588,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -42,9 +42,25 @@\n   medals_og    JSONB\r\n );\r\n \"\"\")\r\n conn.commit()\r\n+cur.execute(\"\"\"\r\n+CREATE TABLE IF NOT EXISTS events (\r\n+    event_id     SERIAL      PRIMARY KEY,\r\n+    athlete_id   INTEGER     NOT NULL\r\n+      REFERENCES athletes(athlete_id)\r\n+      ON DELETE CASCADE,\r\n+    games        TEXT        NOT NULL,\r\n+    discipline   TEXT        NOT NULL,\r\n+    team         TEXT,\r\n+    pos          TEXT,\r\n+    medal        TEXT,\r\n+    used_as      TEXT\r\n+  );\r\n+\"\"\")\r\n+conn.commit()\r\n \r\n+\r\n # ── 2) GET ALL EDITION IDs ────────────────────────────────────────────────────\r\n def get_edition_ids():\r\n     r = requests.get(COUNTRY_URL, headers=HEADERS)\r\n     r.raise_for_status()\r\n@@ -178,8 +194,32 @@\n          nationality, roles, affiliations, medals_og, events)\r\n       VALUES %s\r\n     \"\"\",   to_insert)\r\n     conn.commit()\r\n+    \r\n+        # now also insert their events\r\n+    event_rows = []\r\n+    for aid, used, full, sex, born, died, nat, roles, aff, medals, evts in to_insert:\r\n+        for evt in evts:\r\n+            event_rows.append((\r\n+                aid,\r\n+                evt[\"games\"],\r\n+                evt[\"event\"],\r\n+                evt[\"team\"],\r\n+                evt[\"pos\"],\r\n+                evt[\"medal\"],\r\n+                evt[\"as\"],\r\n+            ))\r\n+\r\n+    if event_rows:\r\n+        execute_values(cur, \"\"\"\r\n+          INSERT INTO events\r\n+            (athlete_id, games, discipline, team, pos, medal, used_as)\r\n+          VALUES %s\r\n+          ON CONFLICT DO NOTHING\r\n+        \"\"\", event_rows)\r\n+        conn.commit()\r\n+\r\n     print(f\"Inserted {len(to_insert)} new athletes.\")\r\n     cur.execute(\"SELECT COUNT(*) FROM athletes\")\r\n     print(\"Total in DB now:\", cur.fetchone()[0])\r\n else:\r\n"
                },
                {
                    "date": 1754750120411,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -154,9 +154,10 @@\n edition_ids = get_edition_ids()\r\n print(\"Found editions:\", edition_ids)\r\n \r\n seen = set()\r\n-to_insert = []\r\n+athlete_rows = []\r\n+event_rows=[]\r\n \r\n for ed in edition_ids:\r\n     for aid in get_athlete_ids_from_edition(ed):\r\n         if aid in seen:\r\n@@ -169,9 +170,9 @@\n             print(f\"→ Athlete {aid} already in DB, skipping.\")\r\n             continue\r\n \r\n         details = fetch_athlete_details(aid)\r\n-        to_insert.append((\r\n+        athlete_rows.append((\r\n             details[\"athlete_id\"],\r\n             details[\"used_name\"],\r\n             details[\"full_name\"],\r\n             details[\"sex\"],\r\n@@ -180,36 +181,36 @@\n             details[\"nationality\"],\r\n             details[\"roles\"],\r\n             details[\"affiliations\"],\r\n             Json(details[\"medals_og\"]),\r\n-            Json(details[\"events\"]),\r\n         ))\r\n+        \r\n+        # 2) many rows for the events table\r\n+        for evt in details[\"events\"]:\r\n+            event_rows.append((\r\n+            details[\"athlete_id\"],      # or aid\r\n+            evt[\"games\"],\r\n+            evt[\"event\"],               # maps to events.discipline\r\n+            evt[\"team\"],\r\n+            evt[\"pos\"],\r\n+            evt[\"medal\"],\r\n+            evt[\"as\"],\r\n+        ))\r\n \r\n         time.sleep(0.5)\r\n     \r\n \r\n-if to_insert:\r\n+if athlete_rows:\r\n     execute_values(cur, \"\"\"\r\n       INSERT INTO athletes\r\n         (athlete_id, used_name, full_name, sex, born, died,\r\n-         nationality, roles, affiliations, medals_og, events)\r\n+         nationality, roles, affiliations, medals_og)\r\n       VALUES %s\r\n-    \"\"\",   to_insert)\r\n+    \"\"\",   athlete_rows)\r\n     conn.commit()\r\n     \r\n         # now also insert their events\r\n     event_rows = []\r\n-    for aid, used, full, sex, born, died, nat, roles, aff, medals, evts in to_insert:\r\n-        for evt in evts:\r\n-            event_rows.append((\r\n-                aid,\r\n-                evt[\"games\"],\r\n-                evt[\"event\"],\r\n-                evt[\"team\"],\r\n-                evt[\"pos\"],\r\n-                evt[\"medal\"],\r\n-                evt[\"as\"],\r\n-            ))\r\n \r\n     if event_rows:\r\n         execute_values(cur, \"\"\"\r\n           INSERT INTO events\r\n@@ -218,9 +219,9 @@\n           ON CONFLICT DO NOTHING\r\n         \"\"\", event_rows)\r\n         conn.commit()\r\n \r\n-    print(f\"Inserted {len(to_insert)} new athletes.\")\r\n+    print(f\"Inserted {len(athlete_rows)} new athletes.\")\r\n     cur.execute(\"SELECT COUNT(*) FROM athletes\")\r\n     print(\"Total in DB now:\", cur.fetchone()[0])\r\n else:\r\n     print(\"No new athletes to insert.\")\r\n"
                },
                {
                    "date": 1754750429690,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -23,9 +23,34 @@\n     \"password\": \"Ayushi11\",\r\n     \"host\":     \"localhost\",\r\n     \"port\":     5432,\r\n }\r\n+def ensure_events_table(cur, conn):\r\n+    # Is the table already there (in public)?\r\n+    cur.execute(\"SELECT to_regclass('public.events');\")\r\n+    exists = cur.fetchone()[0]\r\n \r\n+    if exists is None:\r\n+        print(\"public.events not found; creating...\")\r\n+        cur.execute(\"\"\"\r\n+            CREATE TABLE public.events (\r\n+                event_id   SERIAL PRIMARY KEY,\r\n+                athlete_id INTEGER NOT NULL\r\n+                    REFERENCES public.athletes(athlete_id)\r\n+                    ON DELETE CASCADE,\r\n+                games      TEXT NOT NULL,\r\n+                discipline TEXT NOT NULL,\r\n+                team       TEXT,\r\n+                pos        TEXT,\r\n+                medal      TEXT,\r\n+                used_as    TEXT\r\n+            );\r\n+        \"\"\")\r\n+        conn.commit()\r\n+        print(\"Created public.events\")\r\n+    else:\r\n+        print(\"public.events already exists\")\r\n+\r\n # ── 1) CONNECT & PREPARE TABLE ────────────────────────────────────────────────\r\n conn = psycopg2.connect(**DB_CONFIG)\r\n cur  = conn.cursor()\r\n cur.execute(\"\"\"\r\n@@ -212,9 +237,9 @@\n     event_rows = []\r\n \r\n     if event_rows:\r\n         execute_values(cur, \"\"\"\r\n-          INSERT INTO events\r\n+          INSERT INTO public.events\r\n             (athlete_id, games, discipline, team, pos, medal, used_as)\r\n           VALUES %s\r\n           ON CONFLICT DO NOTHING\r\n         \"\"\", event_rows)\r\n"
                },
                {
                    "date": 1754809787317,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -225,26 +225,25 @@\n     \r\n \r\n if athlete_rows:\r\n     execute_values(cur, \"\"\"\r\n-      INSERT INTO athletes\r\n+        INSERT INTO athletes\r\n         (athlete_id, used_name, full_name, sex, born, died,\r\n-         nationality, roles, affiliations, medals_og)\r\n-      VALUES %s\r\n+        nationality, roles, affiliations, medals_og)\r\n+        VALUES %s\r\n     \"\"\",   athlete_rows)\r\n     conn.commit()\r\n     \r\n         # now also insert their events\r\n-    event_rows = []\r\n \r\n-    if event_rows:\r\n-        execute_values(cur, \"\"\"\r\n-          INSERT INTO public.events\r\n-            (athlete_id, games, discipline, team, pos, medal, used_as)\r\n-          VALUES %s\r\n-          ON CONFLICT DO NOTHING\r\n-        \"\"\", event_rows)\r\n-        conn.commit()\r\n+if event_rows:\r\n+    execute_values(cur, \"\"\"\r\n+        INSERT INTO public.events\r\n+        (athlete_id, games, discipline, team, pos, medal, used_as)\r\n+        VALUES %s\r\n+        ON CONFLICT DO NOTHING\r\n+    \"\"\", event_rows)\r\n+    conn.commit()\r\n \r\n     print(f\"Inserted {len(athlete_rows)} new athletes.\")\r\n     cur.execute(\"SELECT COUNT(*) FROM athletes\")\r\n     print(\"Total in DB now:\", cur.fetchone()[0])\r\n"
                },
                {
                    "date": 1754830708821,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -125,10 +125,19 @@\n         ths=[th.get_text(strip=True) for th in tbl.select(\"th\")]\r\n         #If it starts with Roles and Sex, it's our box\r\n         if ths and ths[0]==\"Roles\" and \"Sex\" in ths:\r\n             for row in tbl.select(\"tr\"):\r\n+                th=row.find(\"th\")\r\n+                td=row.find(\"td\")\r\n+                if not th or not td:\r\n+                    continue\r\n                 key=row.th.get_text(strip=True).lower().replace(\" \",\"_\")\r\n-                val=row.td.get_text(\" \", strip=True)\r\n+                # --- special handling for NOC: prefer the <a> text if present ---\r\n+                if key==\"noc\":\r\n+                    a=td.find(\"a\")\r\n+                    val=row.td.get_text(\" \", strip=True) if a else td.get_text(\" \",strip=True)\r\n+                else:\r\n+                    val=td.get_text(\" \", strip=True)\r\n                 bio[key]=val\r\n             break\r\n         else:\r\n             raise RuntimeError(\"Bio table not found\")\r\n"
                },
                {
                    "date": 1754831510203,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -83,9 +83,15 @@\n   );\r\n \"\"\")\r\n conn.commit()\r\n \r\n-\r\n+def clean_name(s: str) -> str:\r\n+    if not s:\r\n+        return \"\"\r\n+    # remove middle-dots and periods, then collapse spaces\r\n+    s = re.sub(r\"[•·‧\\.]+\", \" \", s)   # covers • (U+2022), · (U+00B7), ‧ (U+2027), .\r\n+    s = re.sub(r\"\\s+\", \" \", s).strip()\r\n+    return s\r\n # ── 2) GET ALL EDITION IDs ────────────────────────────────────────────────────\r\n def get_edition_ids():\r\n     r = requests.get(COUNTRY_URL, headers=HEADERS)\r\n     r.raise_for_status()\r\n"
                },
                {
                    "date": 1754846228309,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,282 @@\n+import re\r\n+import time\r\n+import requests\r\n+from bs4 import BeautifulSoup\r\n+import psycopg2\r\n+from psycopg2.extras import execute_values, Json\r\n+\r\n+# ── CONFIG ───────────────────────────────────────────────────────────────────\r\n+COUNTRY_URL      = \"https://www.olympedia.org/countries/IND/\"\r\n+EDITION_BASE     = COUNTRY_URL + \"editions/\"\r\n+ATHLETE_URL_FMT  = \"https://www.olympedia.org/athletes/{}\"\r\n+HEADERS = {\r\n+    \"User-Agent\": (\r\n+        \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\r\n+        \"AppleWebKit/537.36 (KHTML, like Gecko) \"\r\n+        \"Chrome/120.0.0.0 Safari/537.36\"\r\n+    )\r\n+}\r\n+\r\n+DB_CONFIG = {\r\n+    \"dbname\":   \"olympic_data\",\r\n+    \"user\":     \"postgres\",\r\n+    \"password\": \"Ayushi11\",\r\n+    \"host\":     \"localhost\",\r\n+    \"port\":     5432,\r\n+}\r\n+def ensure_events_table(cur, conn):\r\n+    # Is the table already there (in public)?\r\n+    cur.execute(\"SELECT to_regclass('public.events');\")\r\n+    exists = cur.fetchone()[0]\r\n+\r\n+    if exists is None:\r\n+        print(\"public.events not found; creating...\")\r\n+        cur.execute(\"\"\"\r\n+            CREATE TABLE public.events (\r\n+                event_id   SERIAL PRIMARY KEY,\r\n+                athlete_id INTEGER NOT NULL\r\n+                    REFERENCES public.athletes(athlete_id)\r\n+                    ON DELETE CASCADE,\r\n+                games      TEXT NOT NULL,\r\n+                discipline TEXT NOT NULL,\r\n+                team       TEXT,\r\n+                pos        TEXT,\r\n+                medal      TEXT,\r\n+                used_as    TEXT\r\n+            );\r\n+        \"\"\")\r\n+        conn.commit()\r\n+        print(\"Created public.events\")\r\n+    else:\r\n+        print(\"public.events already exists\")\r\n+\r\n+# ── 1) CONNECT & PREPARE TABLE ────────────────────────────────────────────────\r\n+conn = psycopg2.connect(**DB_CONFIG)\r\n+cur  = conn.cursor()\r\n+cur.execute(\"\"\"\r\n+CREATE TABLE IF NOT EXISTS athletes (\r\n+  athlete_id   INTEGER     PRIMARY KEY,\r\n+  used_name    TEXT,\r\n+  full_name    TEXT,\r\n+  sex          TEXT,\r\n+  born         TEXT,\r\n+  died         TEXT,\r\n+  nationality  TEXT,\r\n+  roles        TEXT,\r\n+  affiliations TEXT,\r\n+  medals_og    JSONB\r\n+);\r\n+\"\"\")\r\n+conn.commit()\r\n+cur.execute(\"\"\"\r\n+CREATE TABLE IF NOT EXISTS events (\r\n+    event_id     SERIAL      PRIMARY KEY,\r\n+    athlete_id   INTEGER     NOT NULL\r\n+      REFERENCES athletes(athlete_id)\r\n+      ON DELETE CASCADE,\r\n+    games        TEXT        NOT NULL,\r\n+    discipline   TEXT        NOT NULL,\r\n+    team         TEXT,\r\n+    pos          TEXT,\r\n+    medal        TEXT,\r\n+    used_as      TEXT\r\n+  );\r\n+\"\"\")\r\n+conn.commit()\r\n+\r\n+def clean_name(s: str) -> str:\r\n+    if not s:\r\n+        return \"\"\r\n+    # remove middle-dots and periods, then collapse spaces\r\n+    s = re.sub(r\"[•·‧\\.]+\", \" \", s)   # covers • (U+2022), · (U+00B7), ‧ (U+2027), .\r\n+    s = re.sub(r\"\\s+\", \" \", s).strip()\r\n+    return s\r\n+# ── 2) GET ALL EDITION IDs ────────────────────────────────────────────────────\r\n+def get_edition_ids():\r\n+    r = requests.get(COUNTRY_URL, headers=HEADERS)\r\n+    r.raise_for_status()\r\n+    soup = BeautifulSoup(r.text, \"html.parser\")\r\n+    ids = {\r\n+      int(m.group(1))\r\n+      for a in soup.select(\"a[href^='/countries/IND/editions/']\")\r\n+      if (m := re.search(r\"/editions/(\\d+)\", a[\"href\"]))\r\n+    }\r\n+    return sorted(ids)\r\n+\r\n+# ── 3) GET ATHLETE IDs FROM AN EDITION ───────────────────────────────────────\r\n+def get_athlete_ids_from_edition(ed_id):\r\n+    url = f\"{EDITION_BASE}{ed_id}\"\r\n+    print(f\"→ Edition {ed_id}: {url}\")\r\n+    r = requests.get(url, headers=HEADERS)\r\n+    r.raise_for_status()\r\n+    soup = BeautifulSoup(r.text, \"html.parser\")\r\n+    return {\r\n+      int(m.group(1))\r\n+      for a in soup.select(\"a[href^='/athletes/']\")\r\n+      if (m := re.match(r\"/athletes/(\\d+)\", a[\"href\"]))\r\n+    }\r\n+\r\n+# ── 4) FETCH & PARSE ATHLETE DETAILS ─────────────────────────────────────────\r\n+def fetch_athlete_details(aid):\r\n+    print(f\"    Fetching athlete {aid}\")\r\n+    r    = requests.get(ATHLETE_URL_FMT.format(aid), headers=HEADERS)\r\n+    r.raise_for_status()\r\n+    soup = BeautifulSoup(r.text, \"html.parser\")\r\n+    \r\n+    #1) Grab that bio table\r\n+\r\n+    bio = {}\r\n+    for tbl in soup.find_all(\"table\"):\r\n+        #Grab all the <th> text from the table\r\n+        ths=[th.get_text(strip=True) for th in tbl.select(\"th\")]\r\n+        #If it starts with Roles and Sex, it's our box\r\n+        if ths and ths[0]==\"Roles\" and \"Sex\" in ths:\r\n+            for row in tbl.select(\"tr\"):\r\n+                th=row.find(\"th\")\r\n+                td=row.find(\"td\")\r\n+                if not th or not td:\r\n+                    continue\r\n+                key=row.th.get_text(strip=True).lower().replace(\" \",\"_\")\r\n+                # --- special handling for NOC: prefer the <a> text if present ---\r\n+                if key==\"noc\":\r\n+                    a=td.find(\"a\")\r\n+                    val=row.td.get_text(\" \", strip=True) if a else td.get_text(\" \",strip=True)\r\n+                else:\r\n+                    val=td.get_text(\" \", strip=True)\r\n+                bio[key]=val\r\n+            break\r\n+        else:\r\n+            raise RuntimeError(\"Bio table not found\")\r\n+    \r\n+    medals={}\r\n+    medals_tbl=soup.select_one(\"table.medals-OG, table.medals.OG\")\r\n+    # Fallback: look for a small 2-column table whose first header is “Gold”\r\n+    if not medals_tbl:\r\n+        for t in soup.find_all(\"table\"):\r\n+            heads=[th.get_text(strip=True).lower() for th in t.select(\"tr th\")]\r\n+            if heads and heads[0]==\"gold\":\r\n+                medals_tbl=t\r\n+                break\r\n+    if medals_tbl:\r\n+        for tr in medals_tbl.select(\"tr\"):\r\n+            th=tr.find(\"th\")\r\n+            td=tr.find(\"td\")\r\n+            if not tr or not td:\r\n+                continue\r\n+            label=th.get_text(strip=True).capitalize()\r\n+            m=re.search(r\"\\d+\", td.get_text())\r\n+            if m:\r\n+                medals[label]=int(m.group())\r\n+\r\n+                \r\n+    events=[]\r\n+    #Locate the results table(first table after h2 that says \"Results\")\r\n+    hdr=soup.find(\"h2\",string=lambda t:t and \"Results\" in t)\r\n+    res_tbl=hdr.find_next_sibling(\"table\") if hdr else None\r\n+    \r\n+    if res_tbl:\r\n+        #Skip the header row\r\n+        for tr in res_tbl.select(\"tbody tr\"):\r\n+            tds=tr.select(\"td\")\r\n+            if len(tds) >= 6:\r\n+                event_entry = {\r\n+                    \"games\":   tds[0].get_text(\" \", strip=True),\r\n+                    \"event\":   tds[1].get_text(\" \", strip=True),\r\n+                    \"team\":    tds[2].get_text(\" \", strip=True),\r\n+                    \"pos\":     tds[3].get_text(\" \", strip=True),\r\n+                    \"medal\":   tds[4].get_text(\" \", strip=True),\r\n+                    \"as\":      tds[5].get_text(\" \", strip=True),\r\n+                }\r\n+                events.append(event_entry)\r\n+\r\n+    return {\r\n+        \"athlete_id\":   aid,\r\n+        \"used_name\":    clean_name(bio.get(\"used_name\", \"\")),\r\n+        \"full_name\":    clean_name(bio.get(\"full_name\", \"\")),\r\n+        \"sex\":          bio.get(\"sex\", \"\"),\r\n+        \"born\":         bio.get(\"born\", \"\"),\r\n+        \"died\":         bio.get(\"died\", \"\"),\r\n+        \"nationality\":  bio.get(\"nationality\", \"\"),\r\n+        \"roles\":        bio.get(\"roles\", \"\"),\r\n+        \"affiliations\": bio.get(\"affiliations\", \"\"),\r\n+        \"medals_og\":    medals,\r\n+        \"events\":       events,\r\n+    }\r\n+\r\n+# ── 5) MAIN LOOP: COLLECT, CHECK DB, SCRAPE, BULK INSERT ────────────────────\r\n+edition_ids = get_edition_ids()\r\n+print(\"Found editions:\", edition_ids)\r\n+\r\n+seen = set()\r\n+athlete_rows = []\r\n+event_rows=[]\r\n+\r\n+for ed in edition_ids:\r\n+    for aid in get_athlete_ids_from_edition(ed):\r\n+        if aid in seen:\r\n+            continue\r\n+        seen.add(aid)\r\n+\r\n+        # ← DB check comes *before* any network call to athlete details\r\n+        cur.execute(\"SELECT 1 FROM athletes WHERE athlete_id=%s\", (aid,))\r\n+        if cur.fetchone():\r\n+            print(f\"→ Athlete {aid} already in DB, skipping.\")\r\n+            continue\r\n+\r\n+        details = fetch_athlete_details(aid)\r\n+        athlete_rows.append((\r\n+            details[\"athlete_id\"],\r\n+            details[\"used_name\"],\r\n+            details[\"full_name\"],\r\n+            details[\"sex\"],\r\n+            details[\"born\"],\r\n+            details[\"died\"],\r\n+            details[\"nationality\"],\r\n+            details[\"roles\"],\r\n+            details[\"affiliations\"],\r\n+            Json(details[\"medals_og\"]),\r\n+        ))\r\n+        \r\n+        # 2) many rows for the events table\r\n+        for evt in details[\"events\"]:\r\n+            event_rows.append((\r\n+            details[\"athlete_id\"],      # or aid\r\n+            evt[\"games\"],\r\n+            evt[\"event\"],               # maps to events.discipline\r\n+            evt[\"team\"],\r\n+            evt[\"pos\"],\r\n+            evt[\"medal\"],\r\n+            evt[\"as\"],\r\n+        ))\r\n+\r\n+        time.sleep(0.5)\r\n+    \r\n+\r\n+if athlete_rows:\r\n+    execute_values(cur, \"\"\"\r\n+        INSERT INTO athletes\r\n+        (athlete_id, used_name, full_name, sex, born, died,\r\n+        nationality, roles, affiliations, medals_og)\r\n+        VALUES %s\r\n+    \"\"\",   athlete_rows)\r\n+    conn.commit()\r\n+    \r\n+        # now also insert their events\r\n+\r\n+if event_rows:\r\n+    execute_values(cur, \"\"\"\r\n+        INSERT INTO public.events\r\n+        (athlete_id, games, discipline, team, pos, medal, used_as)\r\n+        VALUES %s\r\n+        ON CONFLICT DO NOTHING\r\n+    \"\"\", event_rows)\r\n+    conn.commit()\r\n+\r\n+    print(f\"Inserted {len(athlete_rows)} new athletes.\")\r\n+    cur.execute(\"SELECT COUNT(*) FROM athletes\")\r\n+    print(\"Total in DB now:\", cur.fetchone()[0])\r\n+else:\r\n+    print(\"No new athletes to insert.\")\r\n+\r\n+cur.close()\r\n+conn.close()\r\n"
                },
                {
                    "date": 1754846237430,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -279,273 +279,4 @@\n     print(\"No new athletes to insert.\")\r\n \r\n cur.close()\r\n conn.close()\r\n-import re\r\n-import time\r\n-import requests\r\n-from bs4 import BeautifulSoup\r\n-import psycopg2\r\n-from psycopg2.extras import execute_values, Json\r\n-\r\n-# ── CONFIG ───────────────────────────────────────────────────────────────────\r\n-COUNTRY_URL      = \"https://www.olympedia.org/countries/IND/\"\r\n-EDITION_BASE     = COUNTRY_URL + \"editions/\"\r\n-ATHLETE_URL_FMT  = \"https://www.olympedia.org/athletes/{}\"\r\n-HEADERS = {\r\n-    \"User-Agent\": (\r\n-        \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\r\n-        \"AppleWebKit/537.36 (KHTML, like Gecko) \"\r\n-        \"Chrome/120.0.0.0 Safari/537.36\"\r\n-    )\r\n-}\r\n-\r\n-DB_CONFIG = {\r\n-    \"dbname\":   \"olympic_data\",\r\n-    \"user\":     \"postgres\",\r\n-    \"password\": \"Ayushi11\",\r\n-    \"host\":     \"localhost\",\r\n-    \"port\":     5432,\r\n-}\r\n-def ensure_events_table(cur, conn):\r\n-    # Is the table already there (in public)?\r\n-    cur.execute(\"SELECT to_regclass('public.events');\")\r\n-    exists = cur.fetchone()[0]\r\n-\r\n-    if exists is None:\r\n-        print(\"public.events not found; creating...\")\r\n-        cur.execute(\"\"\"\r\n-            CREATE TABLE public.events (\r\n-                event_id   SERIAL PRIMARY KEY,\r\n-                athlete_id INTEGER NOT NULL\r\n-                    REFERENCES public.athletes(athlete_id)\r\n-                    ON DELETE CASCADE,\r\n-                games      TEXT NOT NULL,\r\n-                discipline TEXT NOT NULL,\r\n-                team       TEXT,\r\n-                pos        TEXT,\r\n-                medal      TEXT,\r\n-                used_as    TEXT\r\n-            );\r\n-        \"\"\")\r\n-        conn.commit()\r\n-        print(\"Created public.events\")\r\n-    else:\r\n-        print(\"public.events already exists\")\r\n-\r\n-# ── 1) CONNECT & PREPARE TABLE ────────────────────────────────────────────────\r\n-conn = psycopg2.connect(**DB_CONFIG)\r\n-cur  = conn.cursor()\r\n-cur.execute(\"\"\"\r\n-CREATE TABLE IF NOT EXISTS athletes (\r\n-  athlete_id   INTEGER     PRIMARY KEY,\r\n-  used_name    TEXT,\r\n-  full_name    TEXT,\r\n-  sex          TEXT,\r\n-  born         TEXT,\r\n-  died         TEXT,\r\n-  nationality  TEXT,\r\n-  roles        TEXT,\r\n-  affiliations TEXT,\r\n-  medals_og    JSONB\r\n-);\r\n-\"\"\")\r\n-conn.commit()\r\n-cur.execute(\"\"\"\r\n-CREATE TABLE IF NOT EXISTS events (\r\n-    event_id     SERIAL      PRIMARY KEY,\r\n-    athlete_id   INTEGER     NOT NULL\r\n-      REFERENCES athletes(athlete_id)\r\n-      ON DELETE CASCADE,\r\n-    games        TEXT        NOT NULL,\r\n-    discipline   TEXT        NOT NULL,\r\n-    team         TEXT,\r\n-    pos          TEXT,\r\n-    medal        TEXT,\r\n-    used_as      TEXT\r\n-  );\r\n-\"\"\")\r\n-conn.commit()\r\n-\r\n-def clean_name(s: str) -> str:\r\n-    if not s:\r\n-        return \"\"\r\n-    # remove middle-dots and periods, then collapse spaces\r\n-    s = re.sub(r\"[•·‧\\.]+\", \" \", s)   # covers • (U+2022), · (U+00B7), ‧ (U+2027), .\r\n-    s = re.sub(r\"\\s+\", \" \", s).strip()\r\n-    return s\r\n-# ── 2) GET ALL EDITION IDs ────────────────────────────────────────────────────\r\n-def get_edition_ids():\r\n-    r = requests.get(COUNTRY_URL, headers=HEADERS)\r\n-    r.raise_for_status()\r\n-    soup = BeautifulSoup(r.text, \"html.parser\")\r\n-    ids = {\r\n-      int(m.group(1))\r\n-      for a in soup.select(\"a[href^='/countries/IND/editions/']\")\r\n-      if (m := re.search(r\"/editions/(\\d+)\", a[\"href\"]))\r\n-    }\r\n-    return sorted(ids)\r\n-\r\n-# ── 3) GET ATHLETE IDs FROM AN EDITION ───────────────────────────────────────\r\n-def get_athlete_ids_from_edition(ed_id):\r\n-    url = f\"{EDITION_BASE}{ed_id}\"\r\n-    print(f\"→ Edition {ed_id}: {url}\")\r\n-    r = requests.get(url, headers=HEADERS)\r\n-    r.raise_for_status()\r\n-    soup = BeautifulSoup(r.text, \"html.parser\")\r\n-    return {\r\n-      int(m.group(1))\r\n-      for a in soup.select(\"a[href^='/athletes/']\")\r\n-      if (m := re.match(r\"/athletes/(\\d+)\", a[\"href\"]))\r\n-    }\r\n-\r\n-# ── 4) FETCH & PARSE ATHLETE DETAILS ─────────────────────────────────────────\r\n-def fetch_athlete_details(aid):\r\n-    print(f\"    Fetching athlete {aid}\")\r\n-    r    = requests.get(ATHLETE_URL_FMT.format(aid), headers=HEADERS)\r\n-    r.raise_for_status()\r\n-    soup = BeautifulSoup(r.text, \"html.parser\")\r\n-    \r\n-    #1) Grab that bio table\r\n-\r\n-    bio = {}\r\n-    for tbl in soup.find_all(\"table\"):\r\n-        #Grab all the <th> text from the table\r\n-        ths=[th.get_text(strip=True) for th in tbl.select(\"th\")]\r\n-        #If it starts with Roles and Sex, it's our box\r\n-        if ths and ths[0]==\"Roles\" and \"Sex\" in ths:\r\n-            for row in tbl.select(\"tr\"):\r\n-                th=row.find(\"th\")\r\n-                td=row.find(\"td\")\r\n-                if not th or not td:\r\n-                    continue\r\n-                key=row.th.get_text(strip=True).lower().replace(\" \",\"_\")\r\n-                # --- special handling for NOC: prefer the <a> text if present ---\r\n-                if key==\"noc\":\r\n-                    a=td.find(\"a\")\r\n-                    val=row.td.get_text(\" \", strip=True) if a else td.get_text(\" \",strip=True)\r\n-                else:\r\n-                    val=td.get_text(\" \", strip=True)\r\n-                bio[key]=val\r\n-            break\r\n-        else:\r\n-            raise RuntimeError(\"Bio table not found\")\r\n-\r\n-    medals = {}\r\n-    # it's the <table class=\"medals OG\"> in the sidebar\r\n-    for tbl in soup.select(\"table.medals-OG\"):\r\n-        for tr in tbl.select(\"tr\"):\r\n-            cols = tr.select(\"th, td\")\r\n-            if len(cols) == 2:\r\n-                medals[cols[0].get_text(strip=True)] = int(cols[1].get_text(strip=True))\r\n-                \r\n-    events=[]\r\n-    #Locate the results table(first table after h2 that says \"Results\")\r\n-    hdr=soup.find(\"h2\",string=lambda t:t and \"Results\" in t)\r\n-    res_tbl=hdr.find_next_sibling(\"table\") if hdr else None\r\n-    \r\n-    if res_tbl:\r\n-        #Skip the header row\r\n-        for tr in res_tbl.select(\"tbody tr\"):\r\n-            tds=tr.select(\"td\")\r\n-            if len(tds) >= 6:\r\n-                event_entry = {\r\n-                    \"games\":   tds[0].get_text(\" \", strip=True),\r\n-                    \"event\":   tds[1].get_text(\" \", strip=True),\r\n-                    \"team\":    tds[2].get_text(\" \", strip=True),\r\n-                    \"pos\":     tds[3].get_text(\" \", strip=True),\r\n-                    \"medal\":   tds[4].get_text(\" \", strip=True),\r\n-                    \"as\":      tds[5].get_text(\" \", strip=True),\r\n-                }\r\n-                events.append(event_entry)\r\n-\r\n-    return {\r\n-        \"athlete_id\":   aid,\r\n-        \"used_name\":    bio.get(\"used_name\", \"\"),\r\n-        \"full_name\":    bio.get(\"full_name\", \"\"),\r\n-        \"sex\":          bio.get(\"sex\", \"\"),\r\n-        \"born\":         bio.get(\"born\", \"\"),\r\n-        \"died\":         bio.get(\"died\", \"\"),\r\n-        \"nationality\":  bio.get(\"nationality\", \"\"),\r\n-        \"roles\":        bio.get(\"roles\", \"\"),\r\n-        \"affiliations\": bio.get(\"affiliations\", \"\"),\r\n-        \"medals_og\":    medals,\r\n-        \"events\":       events,\r\n-    }\r\n-\r\n-# ── 5) MAIN LOOP: COLLECT, CHECK DB, SCRAPE, BULK INSERT ────────────────────\r\n-edition_ids = get_edition_ids()\r\n-print(\"Found editions:\", edition_ids)\r\n-\r\n-seen = set()\r\n-athlete_rows = []\r\n-event_rows=[]\r\n-\r\n-for ed in edition_ids:\r\n-    for aid in get_athlete_ids_from_edition(ed):\r\n-        if aid in seen:\r\n-            continue\r\n-        seen.add(aid)\r\n-\r\n-        # ← DB check comes *before* any network call to athlete details\r\n-        cur.execute(\"SELECT 1 FROM athletes WHERE athlete_id=%s\", (aid,))\r\n-        if cur.fetchone():\r\n-            print(f\"→ Athlete {aid} already in DB, skipping.\")\r\n-            continue\r\n-\r\n-        details = fetch_athlete_details(aid)\r\n-        athlete_rows.append((\r\n-            details[\"athlete_id\"],\r\n-            details[\"used_name\"],\r\n-            details[\"full_name\"],\r\n-            details[\"sex\"],\r\n-            details[\"born\"],\r\n-            details[\"died\"],\r\n-            details[\"nationality\"],\r\n-            details[\"roles\"],\r\n-            details[\"affiliations\"],\r\n-            Json(details[\"medals_og\"]),\r\n-        ))\r\n-        \r\n-        # 2) many rows for the events table\r\n-        for evt in details[\"events\"]:\r\n-            event_rows.append((\r\n-            details[\"athlete_id\"],      # or aid\r\n-            evt[\"games\"],\r\n-            evt[\"event\"],               # maps to events.discipline\r\n-            evt[\"team\"],\r\n-            evt[\"pos\"],\r\n-            evt[\"medal\"],\r\n-            evt[\"as\"],\r\n-        ))\r\n-\r\n-        time.sleep(0.5)\r\n-    \r\n-\r\n-if athlete_rows:\r\n-    execute_values(cur, \"\"\"\r\n-        INSERT INTO athletes\r\n-        (athlete_id, used_name, full_name, sex, born, died,\r\n-        nationality, roles, affiliations, medals_og)\r\n-        VALUES %s\r\n-    \"\"\",   athlete_rows)\r\n-    conn.commit()\r\n-    \r\n-        # now also insert their events\r\n-\r\n-if event_rows:\r\n-    execute_values(cur, \"\"\"\r\n-        INSERT INTO public.events\r\n-        (athlete_id, games, discipline, team, pos, medal, used_as)\r\n-        VALUES %s\r\n-        ON CONFLICT DO NOTHING\r\n-    \"\"\", event_rows)\r\n-    conn.commit()\r\n-\r\n-    print(f\"Inserted {len(athlete_rows)} new athletes.\")\r\n-    cur.execute(\"SELECT COUNT(*) FROM athletes\")\r\n-    print(\"Total in DB now:\", cur.fetchone()[0])\r\n-else:\r\n-    print(\"No new athletes to insert.\")\r\n-\r\n-cur.close()\r\n-conn.close()\r\n"
                },
                {
                    "date": 1754899847622,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -138,16 +138,14 @@\n                     continue\r\n                 key=row.th.get_text(strip=True).lower().replace(\" \",\"_\")\r\n                 # --- special handling for NOC: prefer the <a> text if present ---\r\n                 if key==\"noc\":\r\n-                    a=td.find(\"a\")\r\n-                    val=row.td.get_text(\" \", strip=True) if a else td.get_text(\" \",strip=True)\r\n+                    a_tag=td.find(\"a\")\r\n+                    val=a_tag.td.get_text(\" \", strip=True) if a_tag else td.get_text(\" \",strip=True)\r\n                 else:\r\n                     val=td.get_text(\" \", strip=True)\r\n                 bio[key]=val\r\n             break\r\n-        else:\r\n-            raise RuntimeError(\"Bio table not found\")\r\n     \r\n     medals={}\r\n     medals_tbl=soup.select_one(\"table.medals-OG, table.medals.OG\")\r\n     # Fallback: look for a small 2-column table whose first header is “Gold”\r\n"
                },
                {
                    "date": 1754902699374,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -139,9 +139,9 @@\n                 key=row.th.get_text(strip=True).lower().replace(\" \",\"_\")\r\n                 # --- special handling for NOC: prefer the <a> text if present ---\r\n                 if key==\"noc\":\r\n                     a_tag=td.find(\"a\")\r\n-                    val=a_tag.td.get_text(\" \", strip=True) if a_tag else td.get_text(\" \",strip=True)\r\n+                    val=a_tag.get_text(\" \", strip=True) if a_tag else td.get_text(\" \",strip=True)\r\n                 else:\r\n                     val=td.get_text(\" \", strip=True)\r\n                 bio[key]=val\r\n             break\r\n"
                },
                {
                    "date": 1754916620601,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -117,91 +117,75 @@\n     }\r\n \r\n # ── 4) FETCH & PARSE ATHLETE DETAILS ─────────────────────────────────────────\r\n def fetch_athlete_details(aid):\r\n-    print(f\"    Fetching athlete {aid}\")\r\n-    r    = requests.get(ATHLETE_URL_FMT.format(aid), headers=HEADERS)\r\n+    r = requests.get(ATHLETE_URL_FMT.format(aid), headers=HEADERS)\r\n     r.raise_for_status()\r\n     soup = BeautifulSoup(r.text, \"html.parser\")\r\n-    \r\n-    #1) Grab that bio table\r\n \r\n+    # Locate the bio table and fill bio dict\r\n     bio = {}\r\n     for tbl in soup.find_all(\"table\"):\r\n-        #Grab all the <th> text from the table\r\n-        ths=[th.get_text(strip=True) for th in tbl.select(\"th\")]\r\n-        #If it starts with Roles and Sex, it's our box\r\n-        if ths and ths[0]==\"Roles\" and \"Sex\" in ths:\r\n+        ths = [th.get_text(strip=True) for th in tbl.select(\"th\")]\r\n+        if ths and ths[0] == \"Roles\" and \"Sex\" in ths:\r\n             for row in tbl.select(\"tr\"):\r\n-                th=row.find(\"th\")\r\n-                td=row.find(\"td\")\r\n-                if not th or not td:\r\n-                    continue\r\n-                key=row.th.get_text(strip=True).lower().replace(\" \",\"_\")\r\n-                # --- special handling for NOC: prefer the <a> text if present ---\r\n-                if key==\"noc\":\r\n-                    a_tag=td.find(\"a\")\r\n-                    val=a_tag.get_text(\" \", strip=True) if a_tag else td.get_text(\" \",strip=True)\r\n+                th = row.find(\"th\")\r\n+                td = row.find(\"td\")\r\n+                key = th.get_text(strip=True).lower().replace(\" \", \"_\")\r\n+                if key == \"noc\":\r\n+                    a = td.find(\"a\")\r\n+                    val = a.get_text(strip=True) if a else td.get_text(\" \", strip=True)\r\n                 else:\r\n-                    val=td.get_text(\" \", strip=True)\r\n-                bio[key]=val\r\n+                    val = td.get_text(\" \", strip=True)\r\n+                bio[key] = val\r\n             break\r\n-    \r\n-    medals={}\r\n-    medals_tbl=soup.select_one(\"table.medals-OG, table.medals.OG\")\r\n-    # Fallback: look for a small 2-column table whose first header is “Gold”\r\n-    if not medals_tbl:\r\n-        for t in soup.find_all(\"table\"):\r\n-            heads=[th.get_text(strip=True).lower() for th in t.select(\"tr th\")]\r\n-            if heads and heads[0]==\"gold\":\r\n-                medals_tbl=t\r\n-                break\r\n+    # Use NOC as nationality if there is no separate nationality row\r\n+    nationality_val = bio.get(\"nationality\") or bio.get(\"noc\", \"\")\r\n+\r\n+    # Parse medals table (handle both class forms)\r\n+    medals = {}\r\n+    medals_tbl = soup.select_one(\"table.medals-OG, table.medals.OG\")\r\n     if medals_tbl:\r\n         for tr in medals_tbl.select(\"tr\"):\r\n-            th=tr.find(\"th\")\r\n-            td=tr.find(\"td\")\r\n-            if not tr or not td:\r\n-                continue\r\n-            label=th.get_text(strip=True).capitalize()\r\n-            m=re.search(r\"\\d+\", td.get_text())\r\n-            if m:\r\n-                medals[label]=int(m.group())\r\n+            th, td = tr.find(\"th\"), tr.find(\"td\")\r\n+            if th and td:\r\n+                label = th.get_text(strip=True).capitalize()\r\n+                match = re.search(r\"\\d+\", td.get_text())\r\n+                if match:\r\n+                    medals[label] = int(match.group())\r\n \r\n-                \r\n-    events=[]\r\n-    #Locate the results table(first table after h2 that says \"Results\")\r\n-    hdr=soup.find(\"h2\",string=lambda t:t and \"Results\" in t)\r\n-    res_tbl=hdr.find_next_sibling(\"table\") if hdr else None\r\n-    \r\n+    # Parse events/results (use hdr.find_next_sibling)\r\n+    events = []\r\n+    hdr = soup.find(\"h2\", string=lambda t: t and \"Results\" in t)\r\n+    res_tbl = hdr.find_next_sibling(\"table\") if hdr else None\r\n     if res_tbl:\r\n-        #Skip the header row\r\n         for tr in res_tbl.select(\"tbody tr\"):\r\n-            tds=tr.select(\"td\")\r\n-            if len(tds) >= 6:\r\n-                event_entry = {\r\n-                    \"games\":   tds[0].get_text(\" \", strip=True),\r\n-                    \"event\":   tds[1].get_text(\" \", strip=True),\r\n-                    \"team\":    tds[2].get_text(\" \", strip=True),\r\n-                    \"pos\":     tds[3].get_text(\" \", strip=True),\r\n-                    \"medal\":   tds[4].get_text(\" \", strip=True),\r\n-                    \"as\":      tds[5].get_text(\" \", strip=True),\r\n-                }\r\n-                events.append(event_entry)\r\n+            cols = tr.select(\"td\")\r\n+            if len(cols) >= 6:\r\n+                events.append({\r\n+                    \"games\": cols[0].get_text(\" \", strip=True),\r\n+                    \"event\": cols[1].get_text(\" \", strip=True),\r\n+                    \"team\":  cols[2].get_text(\" \", strip=True),\r\n+                    \"pos\":   cols[3].get_text(\" \", strip=True),\r\n+                    \"medal\": cols[4].get_text(\" \", strip=True),\r\n+                    \"as\":    cols[5].get_text(\" \", strip=True),\r\n+                })\r\n \r\n     return {\r\n-        \"athlete_id\":   aid,\r\n-        \"used_name\":    clean_name(bio.get(\"used_name\", \"\")),\r\n-        \"full_name\":    clean_name(bio.get(\"full_name\", \"\")),\r\n-        \"sex\":          bio.get(\"sex\", \"\"),\r\n-        \"born\":         bio.get(\"born\", \"\"),\r\n-        \"died\":         bio.get(\"died\", \"\"),\r\n-        \"nationality\":  bio.get(\"nationality\", \"\"),\r\n-        \"roles\":        bio.get(\"roles\", \"\"),\r\n+        \"athlete_id\": aid,\r\n+        \"used_name\":  bio.get(\"used_name\", \"\"),\r\n+        \"full_name\":  bio.get(\"full_name\", \"\"),\r\n+        \"sex\":        bio.get(\"sex\", \"\"),\r\n+        \"born\":       bio.get(\"born\", \"\"),\r\n+        \"died\":       bio.get(\"died\", \"\"),\r\n+        \"nationality\": nationality_val,\r\n+        \"roles\":      bio.get(\"roles\", \"\"),\r\n         \"affiliations\": bio.get(\"affiliations\", \"\"),\r\n-        \"medals_og\":    medals,\r\n-        \"events\":       events,\r\n+        \"medals_og\":  medals,\r\n+        \"events\":     events,\r\n     }\r\n \r\n+\r\n # ── 5) MAIN LOOP: COLLECT, CHECK DB, SCRAPE, BULK INSERT ────────────────────\r\n edition_ids = get_edition_ids()\r\n print(\"Found editions:\", edition_ids)\r\n \r\n"
                },
                {
                    "date": 1754916750562,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -117,75 +117,92 @@\n     }\r\n \r\n # ── 4) FETCH & PARSE ATHLETE DETAILS ─────────────────────────────────────────\r\n def fetch_athlete_details(aid):\r\n-    r = requests.get(ATHLETE_URL_FMT.format(aid), headers=HEADERS)\r\n+    print(f\"    Fetching athlete {aid}\")\r\n+    r    = requests.get(ATHLETE_URL_FMT.format(aid), headers=HEADERS)\r\n     r.raise_for_status()\r\n     soup = BeautifulSoup(r.text, \"html.parser\")\r\n+    \r\n+    #1) Grab that bio table\r\n \r\n-    # Locate the bio table and fill bio dict\r\n     bio = {}\r\n     for tbl in soup.find_all(\"table\"):\r\n-        ths = [th.get_text(strip=True) for th in tbl.select(\"th\")]\r\n-        if ths and ths[0] == \"Roles\" and \"Sex\" in ths:\r\n+        #Grab all the <th> text from the table\r\n+        ths=[th.get_text(strip=True) for th in tbl.select(\"th\")]\r\n+        #If it starts with Roles and Sex, it's our box\r\n+        if ths and ths[0]==\"Roles\" and \"Sex\" in ths:\r\n             for row in tbl.select(\"tr\"):\r\n-                th = row.find(\"th\")\r\n-                td = row.find(\"td\")\r\n-                key = th.get_text(strip=True).lower().replace(\" \", \"_\")\r\n-                if key == \"noc\":\r\n-                    a = td.find(\"a\")\r\n-                    val = a.get_text(strip=True) if a else td.get_text(\" \", strip=True)\r\n+                th=row.find(\"th\")\r\n+                td=row.find(\"td\")\r\n+                if not th or not td:\r\n+                    continue\r\n+                key=row.th.get_text(strip=True).lower().replace(\" \",\"_\")\r\n+                # --- special handling for NOC: prefer the <a> text if present ---\r\n+                if key==\"noc\":\r\n+                    a_tag=td.find(\"a\")\r\n+                    val=a_tag.get_text(\" \", strip=True) if a_tag else td.get_text(\" \",strip=True)\r\n                 else:\r\n-                    val = td.get_text(\" \", strip=True)\r\n-                bio[key] = val\r\n+                    val=td.get_text(\" \", strip=True)\r\n+                bio[key]=val\r\n             break\r\n-    # Use NOC as nationality if there is no separate nationality row\r\n     nationality_val = bio.get(\"nationality\") or bio.get(\"noc\", \"\")\r\n-\r\n-    # Parse medals table (handle both class forms)\r\n-    medals = {}\r\n-    medals_tbl = soup.select_one(\"table.medals-OG, table.medals.OG\")\r\n+    \r\n+    medals={}\r\n+    medals_tbl=soup.select_one(\"table.medals-OG, table.medals.OG\")\r\n+    # Fallback: look for a small 2-column table whose first header is “Gold”\r\n+    if not medals_tbl:\r\n+        for t in soup.find_all(\"table\"):\r\n+            heads=[th.get_text(strip=True).lower() for th in t.select(\"tr th\")]\r\n+            if heads and heads[0]==\"gold\":\r\n+                medals_tbl=t\r\n+                break\r\n     if medals_tbl:\r\n         for tr in medals_tbl.select(\"tr\"):\r\n-            th, td = tr.find(\"th\"), tr.find(\"td\")\r\n-            if th and td:\r\n-                label = th.get_text(strip=True).capitalize()\r\n-                match = re.search(r\"\\d+\", td.get_text())\r\n-                if match:\r\n-                    medals[label] = int(match.group())\r\n+            th=tr.find(\"th\")\r\n+            td=tr.find(\"td\")\r\n+            if not tr or not td:\r\n+                continue\r\n+            label=th.get_text(strip=True).capitalize()\r\n+            m=re.search(r\"\\d+\", td.get_text())\r\n+            if m:\r\n+                medals[label]=int(m.group())\r\n \r\n-    # Parse events/results (use hdr.find_next_sibling)\r\n-    events = []\r\n-    hdr = soup.find(\"h2\", string=lambda t: t and \"Results\" in t)\r\n-    res_tbl = hdr.find_next_sibling(\"table\") if hdr else None\r\n+                \r\n+    events=[]\r\n+    #Locate the results table(first table after h2 that says \"Results\")\r\n+    hdr=soup.find(\"h2\",string=lambda t:t and \"Results\" in t)\r\n+    res_tbl=hdr.find_next_sibling(\"table\") if hdr else None\r\n+    \r\n     if res_tbl:\r\n+        #Skip the header row\r\n         for tr in res_tbl.select(\"tbody tr\"):\r\n-            cols = tr.select(\"td\")\r\n-            if len(cols) >= 6:\r\n-                events.append({\r\n-                    \"games\": cols[0].get_text(\" \", strip=True),\r\n-                    \"event\": cols[1].get_text(\" \", strip=True),\r\n-                    \"team\":  cols[2].get_text(\" \", strip=True),\r\n-                    \"pos\":   cols[3].get_text(\" \", strip=True),\r\n-                    \"medal\": cols[4].get_text(\" \", strip=True),\r\n-                    \"as\":    cols[5].get_text(\" \", strip=True),\r\n-                })\r\n+            tds=tr.select(\"td\")\r\n+            if len(tds) >= 6:\r\n+                event_entry = {\r\n+                    \"games\":   tds[0].get_text(\" \", strip=True),\r\n+                    \"event\":   tds[1].get_text(\" \", strip=True),\r\n+                    \"team\":    tds[2].get_text(\" \", strip=True),\r\n+                    \"pos\":     tds[3].get_text(\" \", strip=True),\r\n+                    \"medal\":   tds[4].get_text(\" \", strip=True),\r\n+                    \"as\":      tds[5].get_text(\" \", strip=True),\r\n+                }\r\n+                events.append(event_entry)\r\n \r\n     return {\r\n-        \"athlete_id\": aid,\r\n-        \"used_name\":  bio.get(\"used_name\", \"\"),\r\n-        \"full_name\":  bio.get(\"full_name\", \"\"),\r\n-        \"sex\":        bio.get(\"sex\", \"\"),\r\n-        \"born\":       bio.get(\"born\", \"\"),\r\n-        \"died\":       bio.get(\"died\", \"\"),\r\n-        \"nationality\": nationality_val,\r\n-        \"roles\":      bio.get(\"roles\", \"\"),\r\n+        \"athlete_id\":   aid,\r\n+        \"used_name\":    clean_name(bio.get(\"used_name\", \"\")),\r\n+        \"full_name\":    clean_name(bio.get(\"full_name\", \"\")),\r\n+        \"sex\":          bio.get(\"sex\", \"\"),\r\n+        \"born\":         bio.get(\"born\", \"\"),\r\n+        \"died\":         bio.get(\"died\", \"\"),\r\n+        \"nationality\":  nationality_val,\r\n+        \"roles\":        bio.get(\"roles\", \"\"),\r\n         \"affiliations\": bio.get(\"affiliations\", \"\"),\r\n-        \"medals_og\":  medals,\r\n-        \"events\":     events,\r\n+        \"medals_og\":    medals,\r\n+        \"events\":       events,\r\n     }\r\n \r\n-\r\n # ── 5) MAIN LOOP: COLLECT, CHECK DB, SCRAPE, BULK INSERT ────────────────────\r\n edition_ids = get_edition_ids()\r\n print(\"Found editions:\", edition_ids)\r\n \r\n"
                },
                {
                    "date": 1754926789988,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -148,15 +148,15 @@\n     nationality_val = bio.get(\"nationality\") or bio.get(\"noc\", \"\")\r\n     \r\n     medals={}\r\n     medals_tbl=soup.select_one(\"table.medals-OG, table.medals.OG\")\r\n-    # Fallback: look for a small 2-column table whose first header is “Gold”\r\n-    if not medals_tbl:\r\n-        for t in soup.find_all(\"table\"):\r\n-            heads=[th.get_text(strip=True).lower() for th in t.select(\"tr th\")]\r\n-            if heads and heads[0]==\"gold\":\r\n-                medals_tbl=t\r\n-                break\r\n+    # # Fallback: look for a small 2-column table whose first header is “Gold”\r\n+    # if not medals_tbl:\r\n+    #     for t in soup.find_all(\"table\"):\r\n+    #         heads=[th.get_text(strip=True).lower() for th in t.select(\"tr th\")]\r\n+    #         if heads and heads[0]==\"gold\":\r\n+    #             medals_tbl=t\r\n+    #             break\r\n     if medals_tbl:\r\n         for tr in medals_tbl.select(\"tr\"):\r\n             th=tr.find(\"th\")\r\n             td=tr.find(\"td\")\r\n"
                },
                {
                    "date": 1754934733609,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -148,15 +148,15 @@\n     nationality_val = bio.get(\"nationality\") or bio.get(\"noc\", \"\")\r\n     \r\n     medals={}\r\n     medals_tbl=soup.select_one(\"table.medals-OG, table.medals.OG\")\r\n-    # # Fallback: look for a small 2-column table whose first header is “Gold”\r\n-    # if not medals_tbl:\r\n-    #     for t in soup.find_all(\"table\"):\r\n-    #         heads=[th.get_text(strip=True).lower() for th in t.select(\"tr th\")]\r\n-    #         if heads and heads[0]==\"gold\":\r\n-    #             medals_tbl=t\r\n-    #             break\r\n+    # Fallback: look for a small 2-column table whose first header is “Gold”\r\n+    if not medals_tbl:\r\n+        for t in soup.find_all(\"table\"):\r\n+            heads=[th.get_text(strip=True).lower() for th in t.select(\"tr th\")]\r\n+            if heads and heads[0]==\"gold\":\r\n+                medals_tbl=t\r\n+                break\r\n     if medals_tbl:\r\n         for tr in medals_tbl.select(\"tr\"):\r\n             th=tr.find(\"th\")\r\n             td=tr.find(\"td\")\r\n"
                },
                {
                    "date": 1754934889848,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -159,14 +159,13 @@\n     if medals_tbl:\r\n         for tr in medals_tbl.select(\"tr\"):\r\n             th=tr.find(\"th\")\r\n             td=tr.find(\"td\")\r\n-            if not tr or not td:\r\n-                continue\r\n-            label=th.get_text(strip=True).capitalize()\r\n-            m=re.search(r\"\\d+\", td.get_text())\r\n-            if m:\r\n-                medals[label]=int(m.group())\r\n+            if tr and td:\r\n+                label=th.get_text(strip=True).capitalize()\r\n+                m=re.search(r\"\\d+\", td.get_text())\r\n+                if m:\r\n+                    medals[label]=int(m.group())\r\n \r\n                 \r\n     events=[]\r\n     #Locate the results table(first table after h2 that says \"Results\")\r\n"
                },
                {
                    "date": 1754962417809,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -159,13 +159,15 @@\n     if medals_tbl:\r\n         for tr in medals_tbl.select(\"tr\"):\r\n             th=tr.find(\"th\")\r\n             td=tr.find(\"td\")\r\n-            if tr and td:\r\n-                label=th.get_text(strip=True).capitalize()\r\n-                m=re.search(r\"\\d+\", td.get_text())\r\n-                if m:\r\n-                    medals[label]=int(m.group())\r\n+            if not th or not td:\r\n+                continue\r\n+            label=th.get_text(strip=True).capitalize()\r\n+            m=re.search(r\"\\d+\", td.get_text())\r\n+            if m:\r\n+                medals[label]=int(m.group())\r\n+    print(f\"    medals parsed for {aid}: {medals}\" if medals else f\"    no medals found for {aid}\")\r\n \r\n                 \r\n     events=[]\r\n     #Locate the results table(first table after h2 that says \"Results\")\r\n"
                },
                {
                    "date": 1754962517783,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -276,7 +276,13 @@\n     cur.execute(\"SELECT COUNT(*) FROM athletes\")\r\n     print(\"Total in DB now:\", cur.fetchone()[0])\r\n else:\r\n     print(\"No new athletes to insert.\")\r\n+    \r\n+details = fetch_athlete_details(143754)\r\n+cur.execute(\r\n+    \"UPDATE athletes SET medals_og=%s WHERE athlete_id=%s\",\r\n+    (Json(details[\"medals_og\"]), details[\"athlete_id\"])\r\n+)\r\n \r\n cur.close()\r\n conn.close()\r\n"
                },
                {
                    "date": 1754966443681,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,292 @@\n+import re\r\n+import time\r\n+import requests\r\n+from bs4 import BeautifulSoup\r\n+import psycopg2\r\n+from psycopg2.extras import execute_values, Json\r\n+\r\n+# ── CONFIG ───────────────────────────────────────────────────────────────────\r\n+COUNTRY_URL      = \"https://www.olympedia.org/countries/IND/\"\r\n+EDITION_BASE     = COUNTRY_URL + \"editions/\"\r\n+ATHLETE_URL_FMT  = \"https://www.olympedia.org/athletes/{}\"\r\n+HEADERS = {\r\n+    \"User-Agent\": (\r\n+        \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\r\n+        \"AppleWebKit/537.36 (KHTML, like Gecko) \"\r\n+        \"Chrome/120.0.0.0 Safari/537.36\"\r\n+    )\r\n+}\r\n+\r\n+DB_CONFIG = {\r\n+    \"dbname\":   \"olympic_data\",\r\n+    \"user\":     \"postgres\",\r\n+    \"password\": \"Ayushi11\",\r\n+    \"host\":     \"localhost\",\r\n+    \"port\":     5432,\r\n+}\r\n+def ensure_events_table(cur, conn):\r\n+    # Is the table already there (in public)?\r\n+    cur.execute(\"SELECT to_regclass('public.events');\")\r\n+    exists = cur.fetchone()[0]\r\n+\r\n+    if exists is None:\r\n+        print(\"public.events not found; creating...\")\r\n+        cur.execute(\"\"\"\r\n+            CREATE TABLE public.events (\r\n+                event_id   SERIAL PRIMARY KEY,\r\n+                athlete_id INTEGER NOT NULL\r\n+                    REFERENCES public.athletes(athlete_id)\r\n+                    ON DELETE CASCADE,\r\n+                games      TEXT NOT NULL,\r\n+                discipline TEXT NOT NULL,\r\n+                team       TEXT,\r\n+                pos        TEXT,\r\n+                medal      TEXT,\r\n+                used_as    TEXT\r\n+            );\r\n+        \"\"\")\r\n+        conn.commit()\r\n+        print(\"Created public.events\")\r\n+    else:\r\n+        print(\"public.events already exists\")\r\n+\r\n+# ── 1) CONNECT & PREPARE TABLE ────────────────────────────────────────────────\r\n+conn = psycopg2.connect(**DB_CONFIG)\r\n+cur  = conn.cursor()\r\n+cur.execute(\"\"\"\r\n+CREATE TABLE IF NOT EXISTS athletes (\r\n+  athlete_id   INTEGER     PRIMARY KEY,\r\n+  used_name    TEXT,\r\n+  full_name    TEXT,\r\n+  sex          TEXT,\r\n+  born         TEXT,\r\n+  died         TEXT,\r\n+  nationality  TEXT,\r\n+  roles        TEXT,\r\n+  affiliations TEXT,\r\n+  medals_og    JSONB\r\n+);\r\n+\"\"\")\r\n+conn.commit()\r\n+cur.execute(\"\"\"\r\n+CREATE TABLE IF NOT EXISTS events (\r\n+    event_id     SERIAL      PRIMARY KEY,\r\n+    athlete_id   INTEGER     NOT NULL\r\n+      REFERENCES athletes(athlete_id)\r\n+      ON DELETE CASCADE,\r\n+    games        TEXT        NOT NULL,\r\n+    discipline   TEXT        NOT NULL,\r\n+    team         TEXT,\r\n+    pos          TEXT,\r\n+    medal        TEXT,\r\n+    used_as      TEXT\r\n+  );\r\n+\"\"\")\r\n+conn.commit()\r\n+\r\n+def clean_name(s: str) -> str:\r\n+    if not s:\r\n+        return \"\"\r\n+    # remove middle-dots and periods, then collapse spaces\r\n+    s = re.sub(r\"[•·‧\\.]+\", \" \", s)   # covers • (U+2022), · (U+00B7), ‧ (U+2027), .\r\n+    s = re.sub(r\"\\s+\", \" \", s).strip()\r\n+    return s\r\n+# ── 2) GET ALL EDITION IDs ────────────────────────────────────────────────────\r\n+def get_edition_ids():\r\n+    r = requests.get(COUNTRY_URL, headers=HEADERS)\r\n+    r.raise_for_status()\r\n+    soup = BeautifulSoup(r.text, \"html.parser\")\r\n+    ids = {\r\n+      int(m.group(1))\r\n+      for a in soup.select(\"a[href^='/countries/IND/editions/']\")\r\n+      if (m := re.search(r\"/editions/(\\d+)\", a[\"href\"]))\r\n+    }\r\n+    return sorted(ids)\r\n+\r\n+# ── 3) GET ATHLETE IDs FROM AN EDITION ───────────────────────────────────────\r\n+def get_athlete_ids_from_edition(ed_id):\r\n+    url = f\"{EDITION_BASE}{ed_id}\"\r\n+    print(f\"→ Edition {ed_id}: {url}\")\r\n+    r = requests.get(url, headers=HEADERS)\r\n+    r.raise_for_status()\r\n+    soup = BeautifulSoup(r.text, \"html.parser\")\r\n+    return {\r\n+      int(m.group(1))\r\n+      for a in soup.select(\"a[href^='/athletes/']\")\r\n+      if (m := re.match(r\"/athletes/(\\d+)\", a[\"href\"]))\r\n+    }\r\n+\r\n+# ── 4) FETCH & PARSE ATHLETE DETAILS ─────────────────────────────────────────\r\n+def fetch_athlete_details(aid):\r\n+    print(f\"    Fetching athlete {aid}\")\r\n+    r    = requests.get(ATHLETE_URL_FMT.format(aid), headers=HEADERS)\r\n+    r.raise_for_status()\r\n+    soup = BeautifulSoup(r.text, \"html.parser\")\r\n+    \r\n+    #1) Grab that bio table\r\n+\r\n+    bio = {}\r\n+    for tbl in soup.find_all(\"table\"):\r\n+        #Grab all the <th> text from the table\r\n+        ths=[th.get_text(strip=True) for th in tbl.select(\"th\")]\r\n+        #If it starts with Roles and Sex, it's our box\r\n+        if ths and ths[0]==\"Roles\" and \"Sex\" in ths:\r\n+            for row in tbl.select(\"tr\"):\r\n+                th=row.find(\"th\")\r\n+                td=row.find(\"td\")\r\n+                if not th or not td:\r\n+                    continue\r\n+                key=row.th.get_text(strip=True).lower().replace(\" \",\"_\")\r\n+                # --- special handling for NOC: prefer the <a> text if present ---\r\n+                if key==\"noc\":\r\n+                    a_tag=td.find(\"a\")\r\n+                    val=a_tag.get_text(\" \", strip=True) if a_tag else td.get_text(\" \",strip=True)\r\n+                else:\r\n+                    val=td.get_text(\" \", strip=True)\r\n+                bio[key]=val\r\n+            break\r\n+    nationality_val = bio.get(\"nationality\") or bio.get(\"noc\", \"\")\r\n+    \r\n+    medals={}\r\n+    medals_tbl=soup.select_one(\"table.medals-OG, table.medals.OG\")\r\n+    # Fallback: look for a small 2-column table whose first header is “Gold”\r\n+    if not medals_tbl:\r\n+        for t in soup.find_all(\"table\"):\r\n+            labels=[]\r\n+            for r in t.select(\"tr\"):\r\n+                c=r.find([\"th\",\"td\"])\r\n+                labels.append(c.get_text(strip=True).lower() if c else \"\")\r\n+            if {\"gold\",\"silver\",\"bronze\"}.issubset(set(labels)):\r\n+                medals_tbl=t\r\n+                break\r\n+    if medals_tbl:\r\n+        for r in medals_tbl.select(\"tr\"):\r\n+            cells=r.find_all([\"th\",\"td\"])\r\n+            if len(cells)<2:\r\n+                continue\r\n+            label=cells[0].get_text(strip=True).capitalize()\r\n+            if label not in {\"Gold\",\"Silver\",\"Bronze\",\"Total\"}:\r\n+                continue\r\n+            m=re.search(r\"\\d+\", cells[1].get_text())\r\n+            if m:\r\n+                medals[label]=int(m.group())\r\n+    print(f\"    medals parsed for {aid}: {medals}\" if medals else f\"    no medals found for {aid}\")\r\n+\r\n+                \r\n+    events=[]\r\n+    #Locate the results table(first table after h2 that says \"Results\")\r\n+    hdr=soup.find(\"h2\",string=lambda t:t and \"Results\" in t)\r\n+    res_tbl=hdr.find_next_sibling(\"table\") if hdr else None\r\n+    \r\n+    if res_tbl:\r\n+        #Skip the header row\r\n+        for tr in res_tbl.select(\"tbody tr\"):\r\n+            tds=tr.select(\"td\")\r\n+            if len(tds) >= 6:\r\n+                event_entry = {\r\n+                    \"games\":   tds[0].get_text(\" \", strip=True),\r\n+                    \"event\":   tds[1].get_text(\" \", strip=True),\r\n+                    \"team\":    tds[2].get_text(\" \", strip=True),\r\n+                    \"pos\":     tds[3].get_text(\" \", strip=True),\r\n+                    \"medal\":   tds[4].get_text(\" \", strip=True),\r\n+                    \"as\":      tds[5].get_text(\" \", strip=True),\r\n+                }\r\n+                events.append(event_entry)\r\n+\r\n+    return {\r\n+        \"athlete_id\":   aid,\r\n+        \"used_name\":    clean_name(bio.get(\"used_name\", \"\")),\r\n+        \"full_name\":    clean_name(bio.get(\"full_name\", \"\")),\r\n+        \"sex\":          bio.get(\"sex\", \"\"),\r\n+        \"born\":         bio.get(\"born\", \"\"),\r\n+        \"died\":         bio.get(\"died\", \"\"),\r\n+        \"nationality\":  nationality_val,\r\n+        \"roles\":        bio.get(\"roles\", \"\"),\r\n+        \"affiliations\": bio.get(\"affiliations\", \"\"),\r\n+        \"medals_og\":    medals,\r\n+        \"events\":       events,\r\n+    }\r\n+\r\n+# ── 5) MAIN LOOP: COLLECT, CHECK DB, SCRAPE, BULK INSERT ────────────────────\r\n+edition_ids = get_edition_ids()\r\n+print(\"Found editions:\", edition_ids)\r\n+\r\n+seen = set()\r\n+athlete_rows = []\r\n+event_rows=[]\r\n+\r\n+for ed in edition_ids:\r\n+    for aid in get_athlete_ids_from_edition(ed):\r\n+        if aid in seen:\r\n+            continue\r\n+        seen.add(aid)\r\n+\r\n+        # ← DB check comes *before* any network call to athlete details\r\n+        cur.execute(\"SELECT 1 FROM athletes WHERE athlete_id=%s\", (aid,))\r\n+        if cur.fetchone():\r\n+            print(f\"→ Athlete {aid} already in DB, skipping.\")\r\n+            continue\r\n+\r\n+        details = fetch_athlete_details(aid)\r\n+        athlete_rows.append((\r\n+            details[\"athlete_id\"],\r\n+            details[\"used_name\"],\r\n+            details[\"full_name\"],\r\n+            details[\"sex\"],\r\n+            details[\"born\"],\r\n+            details[\"died\"],\r\n+            details[\"nationality\"],\r\n+            details[\"roles\"],\r\n+            details[\"affiliations\"],\r\n+            Json(details[\"medals_og\"]),\r\n+        ))\r\n+        \r\n+        # 2) many rows for the events table\r\n+        for evt in details[\"events\"]:\r\n+            event_rows.append((\r\n+            details[\"athlete_id\"],      # or aid\r\n+            evt[\"games\"],\r\n+            evt[\"event\"],               # maps to events.discipline\r\n+            evt[\"team\"],\r\n+            evt[\"pos\"],\r\n+            evt[\"medal\"],\r\n+            evt[\"as\"],\r\n+        ))\r\n+\r\n+        time.sleep(0.5)\r\n+    \r\n+\r\n+if athlete_rows:\r\n+    execute_values(cur, \"\"\"\r\n+        INSERT INTO athletes\r\n+        (athlete_id, used_name, full_name, sex, born, died,\r\n+        nationality, roles, affiliations, medals_og)\r\n+        VALUES %s\r\n+    \"\"\",   athlete_rows)\r\n+    conn.commit()\r\n+    \r\n+        # now also insert their events\r\n+\r\n+if event_rows:\r\n+    execute_values(cur, \"\"\"\r\n+        INSERT INTO public.events\r\n+        (athlete_id, games, discipline, team, pos, medal, used_as)\r\n+        VALUES %s\r\n+        ON CONFLICT DO NOTHING\r\n+    \"\"\", event_rows)\r\n+    conn.commit()\r\n+\r\n+    print(f\"Inserted {len(athlete_rows)} new athletes.\")\r\n+    cur.execute(\"SELECT COUNT(*) FROM athletes\")\r\n+    print(\"Total in DB now:\", cur.fetchone()[0])\r\n+else:\r\n+    print(\"No new athletes to insert.\")\r\n+    \r\n+details = fetch_athlete_details(143754)\r\n+cur.execute(\r\n+    \"UPDATE athletes SET medals_og=%s WHERE athlete_id=%s\",\r\n+    (Json(details[\"medals_og\"]), details[\"athlete_id\"])\r\n+)\r\n+\r\n+cur.close()\r\n+conn.close()\r\n"
                },
                {
                    "date": 1754966452108,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -289,292 +289,4 @@\n )\r\n \r\n cur.close()\r\n conn.close()\r\n-import re\r\n-import time\r\n-import requests\r\n-from bs4 import BeautifulSoup\r\n-import psycopg2\r\n-from psycopg2.extras import execute_values, Json\r\n-\r\n-# ── CONFIG ───────────────────────────────────────────────────────────────────\r\n-COUNTRY_URL      = \"https://www.olympedia.org/countries/IND/\"\r\n-EDITION_BASE     = COUNTRY_URL + \"editions/\"\r\n-ATHLETE_URL_FMT  = \"https://www.olympedia.org/athletes/{}\"\r\n-HEADERS = {\r\n-    \"User-Agent\": (\r\n-        \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\r\n-        \"AppleWebKit/537.36 (KHTML, like Gecko) \"\r\n-        \"Chrome/120.0.0.0 Safari/537.36\"\r\n-    )\r\n-}\r\n-\r\n-DB_CONFIG = {\r\n-    \"dbname\":   \"olympic_data\",\r\n-    \"user\":     \"postgres\",\r\n-    \"password\": \"Ayushi11\",\r\n-    \"host\":     \"localhost\",\r\n-    \"port\":     5432,\r\n-}\r\n-def ensure_events_table(cur, conn):\r\n-    # Is the table already there (in public)?\r\n-    cur.execute(\"SELECT to_regclass('public.events');\")\r\n-    exists = cur.fetchone()[0]\r\n-\r\n-    if exists is None:\r\n-        print(\"public.events not found; creating...\")\r\n-        cur.execute(\"\"\"\r\n-            CREATE TABLE public.events (\r\n-                event_id   SERIAL PRIMARY KEY,\r\n-                athlete_id INTEGER NOT NULL\r\n-                    REFERENCES public.athletes(athlete_id)\r\n-                    ON DELETE CASCADE,\r\n-                games      TEXT NOT NULL,\r\n-                discipline TEXT NOT NULL,\r\n-                team       TEXT,\r\n-                pos        TEXT,\r\n-                medal      TEXT,\r\n-                used_as    TEXT\r\n-            );\r\n-        \"\"\")\r\n-        conn.commit()\r\n-        print(\"Created public.events\")\r\n-    else:\r\n-        print(\"public.events already exists\")\r\n-\r\n-# ── 1) CONNECT & PREPARE TABLE ────────────────────────────────────────────────\r\n-conn = psycopg2.connect(**DB_CONFIG)\r\n-cur  = conn.cursor()\r\n-cur.execute(\"\"\"\r\n-CREATE TABLE IF NOT EXISTS athletes (\r\n-  athlete_id   INTEGER     PRIMARY KEY,\r\n-  used_name    TEXT,\r\n-  full_name    TEXT,\r\n-  sex          TEXT,\r\n-  born         TEXT,\r\n-  died         TEXT,\r\n-  nationality  TEXT,\r\n-  roles        TEXT,\r\n-  affiliations TEXT,\r\n-  medals_og    JSONB\r\n-);\r\n-\"\"\")\r\n-conn.commit()\r\n-cur.execute(\"\"\"\r\n-CREATE TABLE IF NOT EXISTS events (\r\n-    event_id     SERIAL      PRIMARY KEY,\r\n-    athlete_id   INTEGER     NOT NULL\r\n-      REFERENCES athletes(athlete_id)\r\n-      ON DELETE CASCADE,\r\n-    games        TEXT        NOT NULL,\r\n-    discipline   TEXT        NOT NULL,\r\n-    team         TEXT,\r\n-    pos          TEXT,\r\n-    medal        TEXT,\r\n-    used_as      TEXT\r\n-  );\r\n-\"\"\")\r\n-conn.commit()\r\n-\r\n-def clean_name(s: str) -> str:\r\n-    if not s:\r\n-        return \"\"\r\n-    # remove middle-dots and periods, then collapse spaces\r\n-    s = re.sub(r\"[•·‧\\.]+\", \" \", s)   # covers • (U+2022), · (U+00B7), ‧ (U+2027), .\r\n-    s = re.sub(r\"\\s+\", \" \", s).strip()\r\n-    return s\r\n-# ── 2) GET ALL EDITION IDs ────────────────────────────────────────────────────\r\n-def get_edition_ids():\r\n-    r = requests.get(COUNTRY_URL, headers=HEADERS)\r\n-    r.raise_for_status()\r\n-    soup = BeautifulSoup(r.text, \"html.parser\")\r\n-    ids = {\r\n-      int(m.group(1))\r\n-      for a in soup.select(\"a[href^='/countries/IND/editions/']\")\r\n-      if (m := re.search(r\"/editions/(\\d+)\", a[\"href\"]))\r\n-    }\r\n-    return sorted(ids)\r\n-\r\n-# ── 3) GET ATHLETE IDs FROM AN EDITION ───────────────────────────────────────\r\n-def get_athlete_ids_from_edition(ed_id):\r\n-    url = f\"{EDITION_BASE}{ed_id}\"\r\n-    print(f\"→ Edition {ed_id}: {url}\")\r\n-    r = requests.get(url, headers=HEADERS)\r\n-    r.raise_for_status()\r\n-    soup = BeautifulSoup(r.text, \"html.parser\")\r\n-    return {\r\n-      int(m.group(1))\r\n-      for a in soup.select(\"a[href^='/athletes/']\")\r\n-      if (m := re.match(r\"/athletes/(\\d+)\", a[\"href\"]))\r\n-    }\r\n-\r\n-# ── 4) FETCH & PARSE ATHLETE DETAILS ─────────────────────────────────────────\r\n-def fetch_athlete_details(aid):\r\n-    print(f\"    Fetching athlete {aid}\")\r\n-    r    = requests.get(ATHLETE_URL_FMT.format(aid), headers=HEADERS)\r\n-    r.raise_for_status()\r\n-    soup = BeautifulSoup(r.text, \"html.parser\")\r\n-    \r\n-    #1) Grab that bio table\r\n-\r\n-    bio = {}\r\n-    for tbl in soup.find_all(\"table\"):\r\n-        #Grab all the <th> text from the table\r\n-        ths=[th.get_text(strip=True) for th in tbl.select(\"th\")]\r\n-        #If it starts with Roles and Sex, it's our box\r\n-        if ths and ths[0]==\"Roles\" and \"Sex\" in ths:\r\n-            for row in tbl.select(\"tr\"):\r\n-                th=row.find(\"th\")\r\n-                td=row.find(\"td\")\r\n-                if not th or not td:\r\n-                    continue\r\n-                key=row.th.get_text(strip=True).lower().replace(\" \",\"_\")\r\n-                # --- special handling for NOC: prefer the <a> text if present ---\r\n-                if key==\"noc\":\r\n-                    a_tag=td.find(\"a\")\r\n-                    val=a_tag.get_text(\" \", strip=True) if a_tag else td.get_text(\" \",strip=True)\r\n-                else:\r\n-                    val=td.get_text(\" \", strip=True)\r\n-                bio[key]=val\r\n-            break\r\n-    nationality_val = bio.get(\"nationality\") or bio.get(\"noc\", \"\")\r\n-    \r\n-    medals={}\r\n-    medals_tbl=soup.select_one(\"table.medals-OG, table.medals.OG\")\r\n-    # Fallback: look for a small 2-column table whose first header is “Gold”\r\n-    if not medals_tbl:\r\n-        for t in soup.find_all(\"table\"):\r\n-            heads=[th.get_text(strip=True).lower() for th in t.select(\"tr th\")]\r\n-            if heads and heads[0]==\"gold\":\r\n-                medals_tbl=t\r\n-                break\r\n-    if medals_tbl:\r\n-        for tr in medals_tbl.select(\"tr\"):\r\n-            th=tr.find(\"th\")\r\n-            td=tr.find(\"td\")\r\n-            if not th or not td:\r\n-                continue\r\n-            label=th.get_text(strip=True).capitalize()\r\n-            m=re.search(r\"\\d+\", td.get_text())\r\n-            if m:\r\n-                medals[label]=int(m.group())\r\n-    print(f\"    medals parsed for {aid}: {medals}\" if medals else f\"    no medals found for {aid}\")\r\n-\r\n-                \r\n-    events=[]\r\n-    #Locate the results table(first table after h2 that says \"Results\")\r\n-    hdr=soup.find(\"h2\",string=lambda t:t and \"Results\" in t)\r\n-    res_tbl=hdr.find_next_sibling(\"table\") if hdr else None\r\n-    \r\n-    if res_tbl:\r\n-        #Skip the header row\r\n-        for tr in res_tbl.select(\"tbody tr\"):\r\n-            tds=tr.select(\"td\")\r\n-            if len(tds) >= 6:\r\n-                event_entry = {\r\n-                    \"games\":   tds[0].get_text(\" \", strip=True),\r\n-                    \"event\":   tds[1].get_text(\" \", strip=True),\r\n-                    \"team\":    tds[2].get_text(\" \", strip=True),\r\n-                    \"pos\":     tds[3].get_text(\" \", strip=True),\r\n-                    \"medal\":   tds[4].get_text(\" \", strip=True),\r\n-                    \"as\":      tds[5].get_text(\" \", strip=True),\r\n-                }\r\n-                events.append(event_entry)\r\n-\r\n-    return {\r\n-        \"athlete_id\":   aid,\r\n-        \"used_name\":    clean_name(bio.get(\"used_name\", \"\")),\r\n-        \"full_name\":    clean_name(bio.get(\"full_name\", \"\")),\r\n-        \"sex\":          bio.get(\"sex\", \"\"),\r\n-        \"born\":         bio.get(\"born\", \"\"),\r\n-        \"died\":         bio.get(\"died\", \"\"),\r\n-        \"nationality\":  nationality_val,\r\n-        \"roles\":        bio.get(\"roles\", \"\"),\r\n-        \"affiliations\": bio.get(\"affiliations\", \"\"),\r\n-        \"medals_og\":    medals,\r\n-        \"events\":       events,\r\n-    }\r\n-\r\n-# ── 5) MAIN LOOP: COLLECT, CHECK DB, SCRAPE, BULK INSERT ────────────────────\r\n-edition_ids = get_edition_ids()\r\n-print(\"Found editions:\", edition_ids)\r\n-\r\n-seen = set()\r\n-athlete_rows = []\r\n-event_rows=[]\r\n-\r\n-for ed in edition_ids:\r\n-    for aid in get_athlete_ids_from_edition(ed):\r\n-        if aid in seen:\r\n-            continue\r\n-        seen.add(aid)\r\n-\r\n-        # ← DB check comes *before* any network call to athlete details\r\n-        cur.execute(\"SELECT 1 FROM athletes WHERE athlete_id=%s\", (aid,))\r\n-        if cur.fetchone():\r\n-            print(f\"→ Athlete {aid} already in DB, skipping.\")\r\n-            continue\r\n-\r\n-        details = fetch_athlete_details(aid)\r\n-        athlete_rows.append((\r\n-            details[\"athlete_id\"],\r\n-            details[\"used_name\"],\r\n-            details[\"full_name\"],\r\n-            details[\"sex\"],\r\n-            details[\"born\"],\r\n-            details[\"died\"],\r\n-            details[\"nationality\"],\r\n-            details[\"roles\"],\r\n-            details[\"affiliations\"],\r\n-            Json(details[\"medals_og\"]),\r\n-        ))\r\n-        \r\n-        # 2) many rows for the events table\r\n-        for evt in details[\"events\"]:\r\n-            event_rows.append((\r\n-            details[\"athlete_id\"],      # or aid\r\n-            evt[\"games\"],\r\n-            evt[\"event\"],               # maps to events.discipline\r\n-            evt[\"team\"],\r\n-            evt[\"pos\"],\r\n-            evt[\"medal\"],\r\n-            evt[\"as\"],\r\n-        ))\r\n-\r\n-        time.sleep(0.5)\r\n-    \r\n-\r\n-if athlete_rows:\r\n-    execute_values(cur, \"\"\"\r\n-        INSERT INTO athletes\r\n-        (athlete_id, used_name, full_name, sex, born, died,\r\n-        nationality, roles, affiliations, medals_og)\r\n-        VALUES %s\r\n-    \"\"\",   athlete_rows)\r\n-    conn.commit()\r\n-    \r\n-        # now also insert their events\r\n-\r\n-if event_rows:\r\n-    execute_values(cur, \"\"\"\r\n-        INSERT INTO public.events\r\n-        (athlete_id, games, discipline, team, pos, medal, used_as)\r\n-        VALUES %s\r\n-        ON CONFLICT DO NOTHING\r\n-    \"\"\", event_rows)\r\n-    conn.commit()\r\n-\r\n-    print(f\"Inserted {len(athlete_rows)} new athletes.\")\r\n-    cur.execute(\"SELECT COUNT(*) FROM athletes\")\r\n-    print(\"Total in DB now:\", cur.fetchone()[0])\r\n-else:\r\n-    print(\"No new athletes to insert.\")\r\n-    \r\n-details = fetch_athlete_details(143754)\r\n-cur.execute(\r\n-    \"UPDATE athletes SET medals_og=%s WHERE athlete_id=%s\",\r\n-    (Json(details[\"medals_og\"]), details[\"athlete_id\"])\r\n-)\r\n-\r\n-cur.close()\r\n-conn.close()\r\n"
                },
                {
                    "date": 1754978044533,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -275,8 +275,9 @@\n         ON CONFLICT DO NOTHING\r\n     \"\"\", event_rows)\r\n     conn.commit()\r\n \r\n+\r\n     print(f\"Inserted {len(athlete_rows)} new athletes.\")\r\n     cur.execute(\"SELECT COUNT(*) FROM athletes\")\r\n     print(\"Total in DB now:\", cur.fetchone()[0])\r\n else:\r\n@@ -286,7 +287,36 @@\n cur.execute(\r\n     \"UPDATE athletes SET medals_og=%s WHERE athlete_id=%s\",\r\n     (Json(details[\"medals_og\"]), details[\"athlete_id\"])\r\n )\r\n+# ← Place the rollup HERE (outside the if)\r\n+cur.execute(\"\"\"\r\n+WITH ev AS (\r\n+SELECT e.athlete_id,\r\n+        e.discipline, e.games, e.pos, e.medal,\r\n+        concat_ws(' — ', e.games, e.discipline)\r\n+        || COALESCE(' ['||e.pos||']','')\r\n+        || COALESCE(' ['||e.medal||']','') AS ev_str\r\n+FROM public.events e\r\n+),\r\n+roll AS (\r\n+SELECT athlete_id,\r\n+        STRING_AGG(DISTINCT discipline, ', ' ORDER BY discipline) AS disciplines,\r\n+        STRING_AGG(ev_str, ' | ' ORDER BY games, discipline, pos, medal) AS events\r\n+FROM ev\r\n+GROUP BY athlete_id\r\n+)\r\n+UPDATE public.athletes a\r\n+SET disciplines = roll.disciplines,\r\n+    events      = roll.events\r\n+FROM roll\r\n+WHERE roll.athlete_id = a.athlete_id;\r\n \r\n+UPDATE public.athletes a\r\n+SET disciplines = NULL, events = NULL\r\n+WHERE NOT EXISTS (\r\n+SELECT 1 FROM public.events e WHERE e.athlete_id = a.athlete_id\r\n+);\r\n+\"\"\")\r\n+conn.commit()\r\n cur.close()\r\n conn.close()\r\n"
                }
            ],
            "date": 1754545384213,
            "name": "Commit-0",
            "content": "import re\r\nimport time\r\nimport requests\r\nfrom bs4 import BeautifulSoup\r\nimport psycopg2\r\nfrom psycopg2.extras import execute_values, Json\r\n\r\n# ── CONFIG ───────────────────────────────────────────────────────────────────\r\nCOUNTRY_URL      = \"https://www.olympedia.org/countries/IND/\"\r\nEDITION_BASE     = COUNTRY_URL + \"editions/\"\r\nATHLETE_URL_FMT  = \"https://www.olympedia.org/athletes/{}\"\r\nHEADERS = {\r\n    \"User-Agent\": (\r\n        \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\r\n        \"AppleWebKit/537.36 (KHTML, like Gecko) \"\r\n        \"Chrome/120.0.0.0 Safari/537.36\"\r\n    )\r\n}\r\n\r\nDB_CONFIG = {\r\n    \"dbname\":   \"olympic_data\",\r\n    \"user\":     \"postgres\",\r\n    \"password\": \"Ayushi11\",\r\n    \"host\":     \"localhost\",\r\n    \"port\":     5432,\r\n}\r\n\r\n# ── 1) CONNECT & PREPARE TABLE ────────────────────────────────────────────────\r\nconn = psycopg2.connect(**DB_CONFIG)\r\ncur  = conn.cursor()\r\ncur.execute(\"\"\"\r\nCREATE TABLE IF NOT EXISTS athletes (\r\n  athlete_id   INTEGER     PRIMARY KEY,\r\n  used_name    TEXT,\r\n  full_name    TEXT,\r\n  sex          TEXT,\r\n  born         TEXT,\r\n  died         TEXT,\r\n  nationality  TEXT,\r\n  roles        TEXT,\r\n  affiliations TEXT,\r\n  medals_og    JSONB\r\n);\r\n\"\"\")\r\nconn.commit()\r\n\r\n# ── 2) GET ALL EDITION IDs ────────────────────────────────────────────────────\r\ndef get_edition_ids():\r\n    r = requests.get(COUNTRY_URL, headers=HEADERS)\r\n    r.raise_for_status()\r\n    soup = BeautifulSoup(r.text, \"html.parser\")\r\n    ids = {\r\n      int(m.group(1))\r\n      for a in soup.select(\"a[href^='/countries/IND/editions/']\")\r\n      if (m := re.search(r\"/editions/(\\d+)\", a[\"href\"]))\r\n    }\r\n    return sorted(ids)\r\n\r\n# ── 3) GET ATHLETE IDs FROM AN EDITION ───────────────────────────────────────\r\ndef get_athlete_ids_from_edition(ed_id):\r\n    url = f\"{EDITION_BASE}{ed_id}\"\r\n    print(f\"→ Edition {ed_id}: {url}\")\r\n    r = requests.get(url, headers=HEADERS)\r\n    r.raise_for_status()\r\n    soup = BeautifulSoup(r.text, \"html.parser\")\r\n    return {\r\n      int(m.group(1))\r\n      for a in soup.select(\"a[href^='/athletes/']\")\r\n      if (m := re.match(r\"/athletes/(\\d+)\", a[\"href\"]))\r\n    }\r\n\r\n# ── 4) FETCH & PARSE ATHLETE DETAILS ─────────────────────────────────────────\r\ndef fetch_athlete_details(aid):\r\n    print(f\"    Fetching athlete {aid}\")\r\n    r    = requests.get(ATHLETE_URL_FMT.format(aid), headers=HEADERS)\r\n    r.raise_for_status()\r\n    soup = BeautifulSoup(r.text, \"html.parser\")\r\n    \r\n    #1) Grab that bio table\r\n\r\n    bio = {}\r\n    for tbl in soup.find_all(\"table\"):\r\n        #Grab all the <th> text from the table\r\n        ths=[th.get_text(strip=True) for th in tbl.select(\"th\")]\r\n        #If it starts with Roles and Sex, it's our box\r\n        if ths and ths[0]==\"Roles\" and \"Sex\" in ths:\r\n            for row in tbl.select(\"tr\"):\r\n                key=row.th.get_text(strip=True).lower().replace(\" \",\"_\")\r\n                val=row.td.get_text(\" \", strip=True)\r\n                bio[key]=val\r\n            break\r\n        else:\r\n            raise RuntimeError(\"Bio table not found\")\r\n\r\n    medals = {}\r\n    # it's the <table class=\"medals OG\"> in the sidebar\r\n    for tbl in soup.select(\"table.medals-OG\"):\r\n        for tr in tbl.select(\"tr\"):\r\n            cols = tr.select(\"th, td\")\r\n            if len(cols) == 2:\r\n                medals[cols[0].get_text(strip=True)] = int(cols[1].get_text(strip=True))\r\n                \r\n    events=[]\r\n    #Locate the results table(first table after h2 that says \"Results\")\r\n    hdr=soup.find(\"h2\",string=lambda t:t and \"Results\" in t)\r\n    res_tbl=soup.find_next_sibling(\"table\") if hdr else None\r\n    \r\n    if res_tbl:\r\n        #Skip the header row\r\n        for tr in res_tbl.select(\"tbody tr\"):\r\n            tds=tr.select(\"td\")\r\n            if len(tds) >= 6:\r\n                event_entry = {\r\n                    \"games\":   tds[0].get_text(\" \", strip=True),\r\n                    \"event\":   tds[1].get_text(\" \", strip=True),\r\n                    \"team\":    tds[2].get_text(\" \", strip=True),\r\n                    \"pos\":     tds[3].get_text(\" \", strip=True),\r\n                    \"medal\":   tds[4].get_text(\" \", strip=True),\r\n                    \"as\":      tds[5].get_text(\" \", strip=True),\r\n                }\r\n                events.append(event_entry)\r\n\r\n    return {\r\n        \"athlete_id\":   aid,\r\n        \"used_name\":    bio.get(\"used_name\", \"\"),\r\n        \"full_name\":    bio.get(\"full_name\", \"\"),\r\n        \"sex\":          bio.get(\"sex\", \"\"),\r\n        \"born\":         bio.get(\"born\", \"\"),\r\n        \"died\":         bio.get(\"died\", \"\"),\r\n        \"nationality\":  bio.get(\"nationality\", \"\"),\r\n        \"roles\":        bio.get(\"roles\", \"\"),\r\n        \"affiliations\": bio.get(\"affiliations\", \"\"),\r\n        \"medals_og\":    medals,\r\n        \"events\":       events,\r\n    }\r\n\r\n# ── 5) MAIN LOOP: COLLECT, CHECK DB, SCRAPE, BULK INSERT ────────────────────\r\nedition_ids = get_edition_ids()\r\nprint(\"Found editions:\", edition_ids)\r\n\r\nseen = set()\r\nto_insert = []\r\n\r\nfor ed in edition_ids:\r\n    for aid in get_athlete_ids_from_edition(ed):\r\n        if aid in seen:\r\n            continue\r\n        seen.add(aid)\r\n\r\n        # ← DB check comes *before* any network call to athlete details\r\n        cur.execute(\"SELECT 1 FROM athletes WHERE athlete_id=%s\", (aid,))\r\n        if cur.fetchone():\r\n            print(f\"→ Athlete {aid} already in DB, skipping.\")\r\n            continue\r\n\r\n        details = fetch_athlete_details(aid)\r\n        to_insert.append((\r\n            details[\"athlete_id\"],\r\n            details[\"used_name\"],\r\n            details[\"full_name\"],\r\n            details[\"sex\"],\r\n            details[\"born\"],\r\n            details[\"died\"],\r\n            details[\"nationality\"],\r\n            details[\"roles\"],\r\n            details[\"affiliations\"],\r\n            Json(details[\"medals_og\"])\r\n        ))\r\n\r\n        time.sleep(0.5)\r\n    \r\n\r\nif to_insert:\r\n    execute_values(cur, \"\"\"\r\n      INSERT INTO athletes\r\n        (athlete_id, used_name, full_name, sex, born, died,\r\n         nationality, roles, affiliations, medals_og)\r\n      VALUES %s\r\n    \"\"\",   to_insert)\r\n    conn.commit()\r\n    print(f\"Inserted {len(to_insert)} new athletes.\")\r\n    cur.execute(\"SELECT COUNT(*) FROM athletes\")\r\n    print(\"Total in DB now:\", cur.fetchone()[0])\r\nelse:\r\n    print(\"No new athletes to insert.\")\r\n\r\ncur.close()\r\nconn.close()\r\n"
        }
    ]
}